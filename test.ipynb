{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30628642",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9dc4da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ais_dataloader import *\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from plotting_utils import *\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7aeaa839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataframe from data/processed/processed_AIS_df_2024_01_01_2024_01_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling trajectories for each MMSI: 100%|██████████| 3453/3453 [00:01<00:00, 2771.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Dataset Statistics =====\n",
      "Total number of AIS messages: 2128288\n",
      "Number of unique MMSIs: 3453\n",
      "Date range: 2024-01-01 00:00:00 to 2024-01-01 23:59:59\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start='2024-01-01', end='2024-01-01', freq='D')\n",
    "gp_regression_dataset = AISTrajectoryRegressionDataset(date_range, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551b8b6",
   "metadata": {},
   "source": [
    "## Fit GP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1db10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\F'\n",
      "/var/folders/vw/3pp1qrb97m97jj_776599z6c0000gn/T/ipykernel_75181/3892422781.py:14: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  print(f\"\\Fitting GP for trajectory {idx+1}/{num_trajectories} for MMSI {mmsi}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Fitting GP for trajectory 1/10 for MMSI 3660489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GP Training Progress:   0%|          | 0/250 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniconda/base/envs/gp/lib/python3.13/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-03 to the diagonal\n",
      "  warnings.warn(\n",
      "GP Training Progress: 100%|██████████| 250/250 [00:00<00:00, 267.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8208361268043518\n",
      "\\Fitting GP for trajectory 2/10 for MMSI 203661016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GP Training Progress:  82%|████████▏ | 206/250 [00:09<00:02, 17.68it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from multioutput_gp import *\n",
    "\n",
    "num_trajectories = 10\n",
    "models = {}\n",
    "likelihoods = {}\n",
    "losses = {}\n",
    "\n",
    "for idx in range(num_trajectories):\n",
    "    # mmsi, times, state_trajectory = gp_regression_dataset[idx]\n",
    "    mmsi, times, state_trajectory = gp_regression_dataset[idx]\n",
    "    \n",
    "    print(f\"\\nFitting GP for trajectory {idx+1}/{num_trajectories} for MMSI {mmsi}\")\n",
    "    \n",
    "    X = times.detach().unsqueeze(1).to(device)\n",
    "    Y = state_trajectory.detach().to(device)\n",
    "    \n",
    "    num_outputs = Y.shape[1]\n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_outputs, noise_prior=gpytorch.priors.NormalPrior(loc=0.25, scale=0.25)).to(device)\n",
    "    model = MultiOutputExactGPModel(X, Y, likelihood, num_outputs=num_outputs).to(device)\n",
    "\n",
    "    with gpytorch.settings.cholesky_jitter(1e-3):\n",
    "        loss, model, likelihood = train_model(model, likelihood, X, Y, num_epochs=250, lr=0.1)\n",
    "\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    # models.append(model)\n",
    "    # likelihoods.append(likelihood)\n",
    "    # losses.append(loss.item())\n",
    "    models[mmsi] = model\n",
    "    likelihoods[mmsi] = likelihood\n",
    "    losses[mmsi] = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3348467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: likelihood.raw_task_noises                 value = [0.4403277635574341, 0.4598369598388672, 0.4579230844974518, -5.29512882232666, -5.297037124633789, -5.295773983001709]\n",
      "Parameter name: likelihood.raw_noise                       value = [-5.250217914581299]\n",
      "Parameter name: mean_module.base_means.0.raw_constant      value = 0.21668961644172668\n",
      "Parameter name: mean_module.base_means.1.raw_constant      value = 0.07388921827077866\n",
      "Parameter name: mean_module.base_means.2.raw_constant      value = -0.02350754663348198\n",
      "Parameter name: mean_module.base_means.3.raw_constant      value = -0.000836276332847774\n",
      "Parameter name: mean_module.base_means.4.raw_constant      value = 0.000478812784422189\n",
      "Parameter name: mean_module.base_means.5.raw_constant      value = -2.2941880160942674e-05\n",
      "Parameter name: covar_module.task_covar_module.covar_factor value = [[-1.114229440689087], [-0.316337913274765], [0.4232384264469147], [-0.0008093673968687654], [7.027894753264263e-06], [-8.42002009449061e-07]]\n",
      "Parameter name: covar_module.task_covar_module.raw_var     value = [-2.2886738777160645, -3.5112905502319336, -3.733527898788452, -4.985011577606201, -5.484634876251221, -5.948906421661377]\n",
      "Parameter name: covar_module.data_covar_module.kernels.0.raw_lengthscale value = [[1.675382375717163]]\n",
      "Parameter name: covar_module.data_covar_module.kernels.1.raw_variance value = [[-3.2926816940307617]]\n",
      "\n",
      "1.8470107316970825\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param.tolist()}')\n",
    "    \n",
    "print()\n",
    "print(model.covar_module.data_covar_module.kernels[0].lengthscale.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21d291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/gp/lib/python3.13/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-03 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set the model and likelihood to evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Generate test inputs (e.g., evenly spaced time points)\n",
    "test_times = torch.linspace(times.min(), times.max(), 200).unsqueeze(1).to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cholesky_jitter(1e-3):\n",
    "    predictions = likelihood(model(test_times))\n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35f77d",
   "metadata": {},
   "source": [
    "### Plot GP Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# likelihood.eval()\n",
    "# from plotting_utils import *\n",
    "\n",
    "# for mmsi in models:\n",
    "#     model = models[mmsi]\n",
    "#     likelihood = likelihoods[mmsi]\n",
    "#     # Get the corresponding data for this MMSI\n",
    "#     # If you want to use the same train/test split as before:\n",
    "#     times, state_trajectory = None, None\n",
    "#     for entry in gp_regression_dataset:\n",
    "#         if entry[0] == mmsi:\n",
    "#             _, times, state_trajectory = entry\n",
    "#             break\n",
    "#     if times is None:\n",
    "#         continue  # skip if MMSI not found\n",
    "\n",
    "#     train_X = times.clone().detach().unsqueeze(1).cpu()\n",
    "#     train_Y = state_trajectory.clone().detach().cpu()\n",
    "\n",
    "#     test_X = torch.linspace(times.min(), times.max(), 500).unsqueeze(1).to(device)\n",
    "    \n",
    "#     test_Y = eval_model(model, likelihood, test_X)\n",
    "\n",
    "#     plot_gp(train_X, train_Y, test_X, test_Y)\n",
    "#     plot_single_ship_path(mmsi, times, state_trajectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display, clear_output\n",
    "# from plotting_utils import *\n",
    "\n",
    "\n",
    "# def plot_for_mmsi(selected_mmsi):\n",
    "#     clear_output(wait=True)\n",
    "#     model = models[selected_mmsi]\n",
    "#     likelihood = likelihoods[selected_mmsi]\n",
    "#     # Get the corresponding data for this MMSI\n",
    "#     times, state_trajectory = None, None\n",
    "#     for entry in gp_regression_dataset:\n",
    "#         if entry[0] == selected_mmsi:\n",
    "#             _, times, state_trajectory = entry\n",
    "#             break\n",
    "#     if times is None:\n",
    "#         print(\"No data for MMSI:\", selected_mmsi)\n",
    "#         return\n",
    "\n",
    "#     train_X = times.clone().detach().unsqueeze(1).cpu()\n",
    "#     train_Y = state_trajectory.clone().detach().cpu()\n",
    "#     test_X = torch.linspace(times.min(), times.max(), 500).unsqueeze(1).to(device)\n",
    "#     test_Y = eval_model(model, likelihood, test_X)\n",
    "\n",
    "#     plot_gp(train_X, train_Y, test_X, test_Y)\n",
    "#     plot_single_ship_path(selected_mmsi, times, state_trajectory)\n",
    "\n",
    "    \n",
    "# mmsi_dropdown = widgets.Dropdown(\n",
    "#     options=list(models.keys()),\n",
    "#     description='MMSI:',\n",
    "#     disabled=False,\n",
    "# )\n",
    "\n",
    "# widgets.interact(plot_for_mmsi, selected_mmsi=mmsi_dropdown)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184358b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[367669550 367118980 636018568 ... 367619000 309108000 368926390]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Other'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.unique(gp_regression_dataset.df['MMSI'].values))\n",
    "gp_regression_dataset.get_vessel_group_by_mmsi(3660489)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57b1a0",
   "metadata": {},
   "source": [
    "## Create the kernel param to ship mmsi dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702e440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gp_kernel_ship_classification_dataset import *\n",
    "kernel_classification_dataset = GPKernelShipClassificationDataset(gp_regression_dataset, models, device)\n",
    "kernel_classification_dataset.get_unique_group_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8da73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 1.8975 | Accuracy: 0.0000\n",
      "Epoch 2/20 | Loss: 1.8662 | Accuracy: 0.0000\n",
      "Epoch 3/20 | Loss: 1.8351 | Accuracy: 0.0000\n",
      "Epoch 4/20 | Loss: 1.8043 | Accuracy: 0.0000\n",
      "Epoch 5/20 | Loss: 1.7737 | Accuracy: 0.0000\n",
      "Epoch 6/20 | Loss: 1.7433 | Accuracy: 0.0000\n",
      "Epoch 7/20 | Loss: 1.7132 | Accuracy: 0.0000\n",
      "Epoch 8/20 | Loss: 1.6831 | Accuracy: 0.0000\n",
      "Epoch 9/20 | Loss: 1.6535 | Accuracy: 0.0000\n",
      "Epoch 10/20 | Loss: 1.6252 | Accuracy: 0.0000\n",
      "Epoch 11/20 | Loss: 1.5977 | Accuracy: 0.0000\n",
      "Epoch 12/20 | Loss: 1.5703 | Accuracy: 0.0000\n",
      "Epoch 13/20 | Loss: 1.5429 | Accuracy: 0.0000\n",
      "Epoch 14/20 | Loss: 1.5155 | Accuracy: 0.0000\n",
      "Epoch 15/20 | Loss: 1.4881 | Accuracy: 0.5000\n",
      "Epoch 16/20 | Loss: 1.4609 | Accuracy: 1.0000\n",
      "Epoch 17/20 | Loss: 1.4336 | Accuracy: 1.0000\n",
      "Epoch 18/20 | Loss: 1.4063 | Accuracy: 1.0000\n",
      "Epoch 19/20 | Loss: 1.3790 | Accuracy: 1.0000\n",
      "Epoch 20/20 | Loss: 1.3516 | Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from gp_kernel_ship_classification_network import KernelShipClassificationNetwork\n",
    "\n",
    "# Train params\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_loader = DataLoader(kernel_classification_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_classes = max(kernel_classification_dataset.get_unique_group_ids())\n",
    "\n",
    "model = KernelShipClassificationNetwork(input_dim=2, num_classes=num_classes+1).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for mmsi, kernel_params, group_id in train_loader:\n",
    "        kernel_params = kernel_params.to(device)\n",
    "        group_id = group_id.to(device)  # should be LongTensor for CrossEntropyLoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(kernel_params)\n",
    "        loss = criterion(outputs, group_id)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * kernel_params.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == group_id).sum().item()\n",
    "        total += group_id.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
